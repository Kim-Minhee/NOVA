arXiv_ID,Title,Year,Authors,Abstract,Conclusion
2501.03151,Large language models for artificial general intelligence (AGI): A survey of foundational principles and approaches,2025,Alhassan~Mumuni$^1$$^*$~,"Generative artificial intelligence systems based on large-scale pretrained foundation models such as vision-language models, large language models , diffusion models and vision-language-action models have demonstrated the ability to solve complex and truly non-trivial AI problems in a wide variety of domains and contexts. Multimodal large language models , in particular, learn from vast and diverse data sources, allowing rich and nuanced representations of the world and, thereby, providing extensive capabilities, including the ability to reason, engage in meaningful dialog; collaborate with humans and other agents to jointly solve complex problems; and understand social and emotional aspects of humans. Despite this impressive feat, the cognitive abilities of state-of-the-art LLMs trained on large-scale datasets are still superficial and brittle. Consequently, generic LLMs are severely limited in their generalist capabilities. A number of foundational problems —embodiment, symbol grounding, causality and memory — are required to be addressed for LLMs to attain human-level general intelligence. These concepts are more aligned with human cognition and provide LLMs with inherent human-like cognitive properties that support the realization of physically-plausible, semantically meaningful, flexible and more generalizable knowledge and intelligence. In this work, we discuss the aforementioned foundational issues and survey state-of-the art approaches for implementing these concepts in LLMs. Specifically, we discuss how the principles of embodiment, symbol grounding, causality and memory can be leveraged toward the attainment of artificial general intelligence in an organic manner.","In this work we present what we consider the core enablers of robust and sophisticated cognitive capabilities that AI models based on large language models can leverage to achieve artificial general intelligence – embodiment, symbol grounding, causality and memory. While these concepts are by no means the only principles necessary for the realization of general intelligence, they form the fundamental building blocks which are essential for any AI system to achieve general intelligence in dealing with the real world. Integrating these techniques in LLMs an intrinsic way will lead to a fundamentally new set of important characteristics that natively support AGI. The core building blocks and techniques for realizing these principles are already available, at least in rudimentary form. As our understanding of these principles and the techniques for implementing them continue to improve, the prospect of achieving human-level general intelligence in the foreseeable future is within reach."
2501.03142,Co-Activation Graph Analysis of Safety-Verified and Explainable Deep Reinforcement Learning Policies,2025,First Author Name1,"policies can demonstrate unsafe behaviors and are challenging to interpret. To address these challenges, we combine RL policy model checking—a technique for determining whether RL policies exhibit unsafe behaviors—with co-activation graph analysis—a method that maps neural network inner workings by analyzing neuron activation patterns—to gain insight into the safe RL policy's sequential decision-making. This combination lets us interpret the RL policy's inner workings for safe decision-making. We demonstrate its applicability in various experiments","In this paper, we introduced a methodology that integrates RL policy model checking~ with co-activation graph analysis to improve the explainable safety of RL policies. By generating labeled datasets through model checking and local explainable RL methods, we extended co-activation graph analysis~ to apply it within RL safety. Our approach enables examining NN policies by analyzing neuron activation patterns in states associated with specific safety properties and local explainable RL method results. For future work, we plan to examine how co-activation graph analysis can be applied within multi-agent RL settings~ or to be used for safe NN policy pruning~. {"
2501.03187,Turn-based Multi-Agent Reinforcement Learning Model Checking,2025,First Author Name1,,"In this work, we presented an analytical method for model checking TMARL agents. Our method is based on constructing an induced DTMC from the TMARL system and using probabilistic model checking techniques to verify the behavior of the agents. We applied our method to multiple environments and found that it is able to accurately verify the behavior of the TMARL agents. Our method can handle scenarios that can not be verified using naive monolithic model checking methods. However, at some point, our technique is limited by the size of the induced DTMC and the number of TMARL agents in the system. In future work, we plan to extend our method to incorporate safe TMARL approaches. This has been previously done in the single agent RL domain~, and we believe it can also be applied to TMARL systems. We also plan to combine our proposed method with interpretable RL techniques~ to better understand the trained TMARL agents. This could provide valuable insights into the behavior of the agents. {"
2501.02793,Fairness Through Matching,2025,Kunwoong Kim kwkim.online@gmail.com \\ Department of Statistics\\ Seoul National University Insung Kong[1] insung.kong@utwente.nl \\ Department of Applied Mathematics\\ University of Twente Jongjin Lee jjlee\_.lee@samsung.com \\ Samsung Research\\ Minwoo Chae mchae@postech.ac.kr \\ Department of Industrial and Management Engineering\\ Pohang University of Science and Technology Sangchul Park parks@snu.ac.kr \\ School of Law\\ Seoul National University Yongdai Kim[2] ydkim0903@gmail.com \\ Department of Statistics\\ Interdisciplinary Program in Artificial Intelligence\\ Seoul National University,"Group fairness requires that different protected groups, characterized by a given sensitive attribute, receive equal outcomes overall. Typically, the level of group fairness is measured by the statistical gap between predictions from different protected groups. In this study, we reveal an implicit property of existing group fairness measures, which provides an insight into how the group-fair models behave. Then, we develop a new group-fair constraint based on this implicit property to learn group-fair models. To do so, we first introduce a notable theoretical observation: every group-fair model has an implicitly corresponding transport map between the input spaces of each protected group. Based on this observation, we introduce a new group fairness measure termed Matched Demographic Parity , which quantifies the averaged gap between predictions of two individuals matched by a given transport map. Then, we prove that any transport map can be used in MDP to learn group-fair models, and develop a novel algorithm called Fairness Through Matching, which learns a group-fair model using MDP constraint with an user-specified transport map. We specifically propose two favorable types of transport maps for MDP, based on the optimal transport theory, and discuss their advantages. Experiments reveal that FTM successfully trains group-fair models with certain desirable properties by choosing the transport map accordingly.","In this paper, we have discussed the existence of implicit transport maps corresponding to each group-fair model. Specifically, we have introduced a novel group fairness measure named MDP. Building upon MDP, we propose a novel algorithm, FTM, designed for learning group-fair models with high levels of subset fairness. Experimental results demonstrate that FTM with the marginal OT map effectively produces group-fair models with improved levels of subset fairness on various subsets compared to baseline models, while maintaining reasonable prediction performance. Moreover, we have proposed to use the joint OT map to improve the prediction accuracy and equalized odds, compared to the marginal OT map. We suggest several promising topics for future research: Expanding FTM to incorporate other fairness notions would be a valuable avenue for future work. For example, while this paper has focused DP for simplicity and clarity, but applying FTM to Eqopp would be straightforward by restricting the calculation of MDP to instances where $Y=1.$ Exploring scenarios with multiple sensitive attributes, a topic frequently studied in group fairness research, is another valuable direction. Such cases require matching individuals from more than two protected groups, which would be challenging and is therefore left for future work. There may be other transport maps that yield different types of group-fair models, while this paper has only considered two transport maps. Exploring other useful transport maps would yield interesting insights and applications. * The broad goal of this study is to caution users of fair AI models -- such as social planners and courts -- against focusing solely on group fairness without accounting for the risks of potential discrimination, such as subset fairness. Additionally, our study aims to equip them with tools to address these aspects. Even though our study is rather technical, we believe that it can provide a new perspective on algorithmic fairness and could potentially impact policy-making and regulation in related fields. A key social benefit of the proposed methods is that we can train group-fair models with higher levels of subset fairness without needing to collect and process additional sensitive data. By doing so, the proposed algorithm is expected to transcend the fairness-privacy trade-off, making it practical for use without conflicting with data protection laws. Another social impact of our study is that the relationship between transport maps and group-fair models may help us form a new concept of fairness that can be readily accepted by society. Our approach explores the micro-level behavior of a given group-fair model , which could facilitate finding reasonable compromises for existing fairness concepts that may appear paradoxical. * YK was partly supported by the National Research Foundation of Korea grant funded by the Korea government, Institute of Information \& communications Technology Planning \& Evaluation grant funded by the Korea government , and Institute of Information \& communications Technology Planning \& Evaluation grant funded by the Korea government [NO.RS-2021-II211343, Artificial Intelligence Graduate School Program ]. MC was supported by a Korea Institute for Advancement of Technology grant funded by the Korea Government ."
2501.0277,Large language models for artificial general intelligence (AGI): A survey of foundational principles and approaches,2025,Alhassan~Mumuni$^1$$^*$~,"Generative artificial intelligence systems based on large-scale pretrained foundation models such as vision-language models, large language models , diffusion models and vision-language-action models have demonstrated the ability to solve complex and truly non-trivial AI problems in a wide variety of domains and contexts. Multimodal large language models , in particular, learn from vast and diverse data sources, allowing rich and nuanced representations of the world and, thereby, providing extensive capabilities, including the ability to reason, engage in meaningful dialog; collaborate with humans and other agents to jointly solve complex problems; and understand social and emotional aspects of humans. Despite this impressive feat, the cognitive abilities of state-of-the-art LLMs trained on large-scale datasets are still superficial and brittle. Consequently, generic LLMs are severely limited in their generalist capabilities. A number of foundational problems —embodiment, symbol grounding, causality and memory — are required to be addressed for LLMs to attain human-level general intelligence. These concepts are more aligned with human cognition and provide LLMs with inherent human-like cognitive properties that support the realization of physically-plausible, semantically meaningful, flexible and more generalizable knowledge and intelligence. In this work, we discuss the aforementioned foundational issues and survey state-of-the art approaches for implementing these concepts in LLMs. Specifically, we discuss how the principles of embodiment, symbol grounding, causality and memory can be leveraged toward the attainment of artificial general intelligence in an organic manner.","In this work we present what we consider the core enablers of robust and sophisticated cognitive capabilities that AI models based on large language models can leverage to achieve artificial general intelligence – embodiment, symbol grounding, causality and memory. While these concepts are by no means the only principles necessary for the realization of general intelligence, they form the fundamental building blocks which are essential for any AI system to achieve general intelligence in dealing with the real world. Integrating these techniques in LLMs an intrinsic way will lead to a fundamentally new set of important characteristics that natively support AGI. The core building blocks and techniques for realizing these principles are already available, at least in rudimentary form. As our understanding of these principles and the techniques for implementing them continue to improve, the prospect of achieving human-level general intelligence in the foreseeable future is within reach."
2501.02725,\Large {\bf Artificial Intelligence in Creative Industries: Advances Prior to 2025,2025,"Nantheera Anantrasirichai, Fan Zhang, and David Bull \\ MyWorld \\ University of Bristol","The rapid advancements in artificial intelligence , particularly in generative AI and large language models , have profoundly impacted the creative industries by enabling innovative content creation, enhancing workflows, and democratizing access to creative tools. This paper explores the significant technological shifts since our previous review in 2022, highlighting how these developments have expanded creative opportunities and efficiency. These technological advancements have enhanced the capabilities of text-to-image, text-to-video, and multimodal generation technologies. In particular, key breakthroughs in LLMs have established new benchmarks in conversational AI, while advancements in image generators have revolutionized content creation. We also discuss AI integration into post-production workflows, which has significantly accelerated and refined traditional processes. Despite these innovations, challenges remain—particularly for the media industry—due to the demands on communication traffic from creative content. We therefore include data compression and quality assessment in this paper. Furthermore, we highlight the trend toward unified AI frameworks capable of addressing multiple creative tasks and underscore the importance of human oversight to mitigate AI-generated inaccuracies. Finally, we explore AI's future potential in the creative sector, stressing the need to navigate emerging challenges to maximize its benefits while addressing associated risks.","This paper presents a comprehensive review of current AI technologies and their applications that have emerged in recent years. With generative AI, there is a rapid growth in AI usage in the creative sector, and these technologies have significantly advanced the state of the art across various creative applications, including content creation, information analysis, content enhancement, information extraction, and data compression. Through these applications, Generative AI not only broadens creative possibilities but also reduces the manual labor and time traditionally associated with production pipeline, allowing for greater creative experimentation and quicker production cycles. As this technology advances, it promises to unlock even more sophisticated capabilities in the creative industry. However, artists and users need to adapt and learn to use these tools efficiently and effectively."
2501.02711,KG-CF: Knowledge Graph Completion with Context Filtering under the Guidance of Large Language Models,2025,,"Large Language Models have shown impressive performance in various tasks, including knowledge graph completion . However, current studies mostly apply LLMs to classification tasks, like identifying missing triplets, rather than ranking-based tasks, where the model ranks candidate entities based on plausibility. This focus limits the practical use of LLMs in KGC, as real-world applications prioritize highly plausible triplets. Additionally, while graph paths can help infer the existence of missing triplets and improve completion accuracy, they often contain redundant information. To address these issues, we propose KG-CF, a framework tailored for ranking-based KGC tasks. KG-CF leverages LLMs’ reasoning abilities to filter out irrelevant contexts, achieving superior results on real-world datasets. The code and datasets are available at .","This paper presents KG-CF, a knowledge graph completion method that enhances pretrained language models through LLM-guided context filtering. We distill a sequence classifier from an LLM to assess reasoning path validity, enabling high-quality KG context selection for training the BERT scorer. Experiments show KG-CF achieves strong performance across datasets and scenarios. Our approach efficiently applies autoregressive LLMs to entity ranking. We leave the incorporation of varying graph context types to future works."
2501.02497,Large language models for artificial general intelligence (AGI): A survey of foundational principles and approaches,2025,Alhassan~Mumuni$^1$$^*$~,"Generative artificial intelligence systems based on large-scale pretrained foundation models such as vision-language models, large language models , diffusion models and vision-language-action models have demonstrated the ability to solve complex and truly non-trivial AI problems in a wide variety of domains and contexts. Multimodal large language models , in particular, learn from vast and diverse data sources, allowing rich and nuanced representations of the world and, thereby, providing extensive capabilities, including the ability to reason, engage in meaningful dialog; collaborate with humans and other agents to jointly solve complex problems; and understand social and emotional aspects of humans. Despite this impressive feat, the cognitive abilities of state-of-the-art LLMs trained on large-scale datasets are still superficial and brittle. Consequently, generic LLMs are severely limited in their generalist capabilities. A number of foundational problems —embodiment, symbol grounding, causality and memory — are required to be addressed for LLMs to attain human-level general intelligence. These concepts are more aligned with human cognition and provide LLMs with inherent human-like cognitive properties that support the realization of physically-plausible, semantically meaningful, flexible and more generalizable knowledge and intelligence. In this work, we discuss the aforementioned foundational issues and survey state-of-the art approaches for implementing these concepts in LLMs. Specifically, we discuss how the principles of embodiment, symbol grounding, causality and memory can be leveraged toward the attainment of artificial general intelligence in an organic manner.","In this work we present what we consider the core enablers of robust and sophisticated cognitive capabilities that AI models based on large language models can leverage to achieve artificial general intelligence – embodiment, symbol grounding, causality and memory. While these concepts are by no means the only principles necessary for the realization of general intelligence, they form the fundamental building blocks which are essential for any AI system to achieve general intelligence in dealing with the real world. Integrating these techniques in LLMs an intrinsic way will lead to a fundamentally new set of important characteristics that natively support AGI. The core building blocks and techniques for realizing these principles are already available, at least in rudimentary form. As our understanding of these principles and the techniques for implementing them continue to improve, the prospect of achieving human-level general intelligence in the foreseeable future is within reach."
2501.02486,LLMPC: Large Language Model Predictive Control,2025,Gabriel Maher gabriel.d.maher@gmail.com,"Recent advancements in prompting techniques for Large Language Models have improved their reasoning, planning, and action abilities. This paper examines these prompting techniques through the lens of model predictive control . We show that LLMs act as implicit planning cost function minimizers when planning prompts are used. Under our framework we demonstrate that LLM planning performance can be improved further by incorporating real planning cost functions and evaluators.",
2501.02368,Enhancing Workplace Productivity and Well-Being using AI Agents,2025,Dr Ravirajan K \\ Associate Principal \\ LTIMindtree \\ USA \\ ravirajan.k@ltimindtree.com,"This paper discussed about using Artificial Intelligence to enhance workplace productivity and employee well-being. By integrating machine learning techniques with neurobiological data, the proposed approaches ensure alignment with human ethical standards through value alignment models and Hierarchical Reinforcement Learning for autonomous task management. The system utilizes biometric feedback from the employees to generate personalized health prompts, fostering a supportive work environment that encourages physical activity. Additionally, we explore decentralized multi-agent systems for improved collaboration and decision-making frameworks that enhance transparency. Different approaches using ML techniques in hybrid with executing AI agents approaches are discussed. Together, these reviews aims to bring innovations and more productive and health-conscious workplace. AI agents accelerate these outcomes help the HR management and organization to launch the more rationale career progression stream for employees and organizational transformation.",
2501.02221,Enhancing Workplace Productivity and Well-Being using AI Agents,2025,Dr Ravirajan K \\ Associate Principal \\ LTIMindtree \\ USA \\ ravirajan.k@ltimindtree.com,"This paper discussed about using Artificial Intelligence to enhance workplace productivity and employee well-being. By integrating machine learning techniques with neurobiological data, the proposed approaches ensure alignment with human ethical standards through value alignment models and Hierarchical Reinforcement Learning for autonomous task management. The system utilizes biometric feedback from the employees to generate personalized health prompts, fostering a supportive work environment that encourages physical activity. Additionally, we explore decentralized multi-agent systems for improved collaboration and decision-making frameworks that enhance transparency. Different approaches using ML techniques in hybrid with executing AI agents approaches are discussed. Together, these reviews aims to bring innovations and more productive and health-conscious workplace. AI agents accelerate these outcomes help the HR management and organization to launch the more rationale career progression stream for employees and organizational transformation.",
2501.02152,Table as Thought: Exploring Structured Thoughts in LLM Reasoning,2025,"Author 1, ..., Author n \\","Large language models' reasoning abilities benefit from methods that organize their thought processes, such as chain-of-thought prompting, which employs a sequential structure to guide the reasoning process step-by-step. However, existing approaches focus primarily on organizing the sequence of thoughts, leaving structure in individual thought steps underexplored. To address this gap, we propose , a framework inspired by cognitive neuroscience theories on human thought. \ organizes reasoning within a tabular schema, where rows represent sequential thought steps and columns capture critical constraints and contextual information to enhance reasoning. The reasoning process iteratively populates the table until self-verification ensures completeness and correctness. Our experiments show that \ excels in planning tasks and demonstrates a strong potential for enhancing LLM performance in mathematical reasoning compared to unstructured thought baselines. This work provides a novel exploration of refining thought representation within LLMs, paving the way for advancements in reasoning and AI cognition.","We proposed , a novel framework that introduces structured reasoning at the thought level. The framework centers on the design and utilization of table schemas, where the LLM is tasked with constructing a schema and generating structured thoughts based on it. Our results demonstrate that \ excels in constraint planning tasks, showcasing its ability to manage complex constraints effectively. Moreover, the framework exhibits significant potential for further improving performance in math reasoning tasks, particularly in addressing unsolved problems through structured reasoning. Additionally, we conducted detailed analyses of the results, exploring the interplay between schema design, reasoning complexity, and model capabilities. These insights pave the way for future research into the nature and representation of thought processes, offering a promising direction for the development of more robust reasoning frameworks in LLMs."
2501.01992,,2024,,"that allow artificial autonomous agents to reach such agreements, using formal models of argumentation, in particular abstract argumentation and value-based argumentation. We introduce the notions of degrees of satisfaction and agreement, as well as a measure of the impact a value in a value-based argumentation framework has on these notions. We then analyze how degrees of agreement are affected when agreement scenarios are expanded with new information, to shed light on the reliability of partial agreements in dynamic scenarios. An implementation of the introduced concepts is provided as part of an argumentation-based reasoning software library { formal argumentation, dialogues, agreement technologies, group decision-making","This paper provides a formal framework for degrees of agreements in abstract and value-based argumentation dialogues, as well as guarantees with respect to bounds for changes in degrees of agreement, given principle-based constraints. A possible next research step is to assess the computational complexity of determining degrees of satisfaction and agreements, as well as of enforcing relaxed monotony principles; determining degrees of agreement can be computationally costly, as it requires a search through the powerset of an argumentation framework's arguments. Besides this, a range of research directions can be considered promising to further develop the introduced approach. In the theoretical analysis, for the sake of conciseness, the proofs of bounds of changes in degrees of agreement in argumentation-based agreement scenarios are limited to the . An analysis of maximal changes in the degrees of mean and median may be relevant, although intuitively, the bound is of greatest interest. More fundamentally, the research presented in this paper could be extended to align with a novel approach to abstract argumentation in which the semantics order sets of arguments according to their ~. These semantics naturally fit the argumentation-based agreement scenarios this paper introduces, as new measures of satisfaction can be straightforwardly derived from the plausibility orders. A key limitation of our research is the assumption that the agents do not act strategically, i.e., we do not model an agent's preferences over choice options given the preferences of other agents. To achieve this, future work can build upon results in game theory on norm-based equilibria~. There are additional lines of work our approach can be integrated with, e.g., a preference-based argumentation method for multi-criteria decision-making~, which presents an application of formal argumentation to a similar problem, but does not cover degrees of agreement and consistency/relaxed monotony principles, and argumentation context frameworks~, which are, roughly speaking, further extending value-based argumentation frameworks to support distributed argumentation. Crucially, we want to emphasize the need to expand on the initial empirical perspectives that we provide in Section~, ideally utilizing real-world data. Finally, we consider the assessment of the impact of values on collaborative inferences and decisions a subject that invites further study in real-world social contexts. We thank the anonymous reviewers for very detailed feedback that has helped us to substantially improve the presentation of the paper. This work was partially supported by the Wallenberg AI, Autonomous Systems and Software Program funded by the Knut and Alice Wallenberg Foundation."
2501.03229,Gaussian Splatting for Masked Autoencoders,2025,"Jathushan Rajasegaran$^1, 2","This paper explores Masked Autoencoders with Gaussian Splatting. While reconstructive self-supervised learning frameworks such as MAE learns good semantic abstractions, it is not trained for explicit spatial awareness. Our approach, named Gaussian Masked Autoencoder, or GMAE, aims to learn semantic abstractions and spatial understanding jointly. Like MAE, it reconstructs the image end-to-end in the pixel space, but beyond MAE, it also introduces an intermediate, 3D Gaussian-based representation and renders images via splatting. We show that GMAE can enable various zero-shot learning capabilities of spatial understanding while preserving the high-level semantics of self-supervised representation quality from MAE. To our knowledge, we are the beyond optimization-based single-scene reconstructions. We believe GMAE will inspire further research in this direction and contribute to developing next-generation techniques for modeling high-fidelity visual data. More details at .",
2501.03228,LightGNN: Simple Graph Neural Network for Recommendation,2025,Guoxuan Chen,"Graph neural networks have demonstrated superior performance in collaborative recommendation through their ability to conduct high-order representation smoothing, effectively capturing structural information within users' interaction patterns. However, existing GNN paradigms face significant challenges in scalability and robustness when handling large-scale, noisy, and real-world datasets. To address these challenges, we present , a lightweight and distillation-based GNN pruning framework designed to substantially reduce model complexity while preserving essential collaboration modeling capabilities. Our \ framework introduces a computationally efficient pruning module that adaptively identifies and removes redundant edges and embedding entries for model compression. The framework is guided by a resource-friendly hierarchical knowledge distillation objective, whose intermediate layer augments the observed graph to maintain performance, particularly in high-rate compression scenarios. Extensive experiments on public datasets demonstrate 's effectiveness, significantly improving both computational efficiency and recommendation accuracy. Notably, \ achieves an 80\",
2501.03226,Boosting Mathematical Reasoning for Large Language Models via Step-level In-context Learning,2025,"Author 1, ..., Author n \\","For complex mathematical reasoning, a model needs two capabilities: divide and conquer, decomposing a complex problem into multiple steps, and reasoning at each individual step respectively. We have observed that the latter is the core limitation, as models often make various errors during single-step reasoning. An effective way to improve reasoning accuracy is by providing similar examples, known as in-context learning. However, current in-context learning at problem level provides examples prior to reasoning, thus lacking fine-grained guidance during an on-going reasoning process. Moreover, examples retrieved at the problem level may not be entirely consistent. Irrelevant steps may even negatively affect the reasoning for individual steps. To this end, we subdivide in-context learning to the step level. Specifically, we develop a step-level question bank according to reasoning content instead of grammatical separation, and integrate retrieving and imitating similar example steps into an on-going reasoning process to provide fine-grained guidance. Additionally, we implement a first-try strategy to ensure consistency between the retrieved steps and the current reasoning step. Our strategy has shown the superiority to problem-level in-context learning for about on GPT-4o. In addition, our approach can be applied to Monte Carlo Tree Search methods to enhance both the reasoning capability of the inference model and the evaluative capability of the critic model. Cutting-edge large language models demonstrate promising performance in solving complex math problems with a divide-and-conquer pipeline and the assistance of in-context learning examples. However, their potential for improvement is limited by two critical problems within their ICL examples: granularity-mismatch and the ensuing negative-effect noise problem. Specifically, the LLMs are capable of the dividing process yet mostly failed by inaccurate reasoning within a few conquer steps, while the ICL examples retrieved in question-grained sometimes lack relevant steps for a specific challenging reasoning step. Further, this disconnect may hinder the correct reasoning due to its irrelevance. To this end, we focus on improving the reasoning quality within each step and present BoostStep. BoostStep aligns the granularity between the retrieving and reasoning on step grained, and provides highly related ICL examples for each reasoning step with a novel `first-try' strategy. BoostStep provides more relevant examples than the coarse question-grained strategy, enhancing the model reasoning quality within each step steadily. BoostStep is a general and robust reasoning-enhancing method that not only improves standalone reasoning performance but also integrates seamlessly with Monte Carlo Tree Search methods to refine both candidate generation and decision-making. Quantitatively, it improves GPT-4o and Qwen2.5-Math-72B by 3.6\","We propose step-level in-context learning, which provides real-time, fine-grained guidance during the reasoning process by searching for similar steps according to the first-try reasoning attempt. This approach improves the model's reasoning capabilities and reduces the dependency on the similarity of example problem set, thereby increasing the generalizability of in-context learning. Moreover, our method can also enhance the reasoning and evaluation capability of Monte Carlo Tree Search by introducing similar steps in reasoning and verifying phases respectively, thereby improving the overall reasoning correctness. Currently, our example problem bank is entirely sourced from PRM800k, resulting in a relatively homogeneous distribution of example problems and example steps. Furthermore, the TF-IDF retriever is based on modeling language term frequency directly and lacks an understanding of mathematical content, which limits its retrieval capabilities on math problems."
2501.03225,,2025,,,
